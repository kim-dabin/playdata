# 하둡의 개요#2

- NoSQL 
  - 단순히 키와 값의 쌍으로 이루어져 있음
  - join이 없음
  - 데이터를 하나의 집합된 형태로 저장 
  - sharing: 데이터를 분할해서 다른 서버에 나누어 저장 
- RDBMS
  - 엔티티 간의 관계에 중점을 두고 테이블 구조를 설계하는 방식 
  - 데이터가 여러 행(row)으로 존재함 
  - 핵심 데이터 관리(데이터 무결성과 정합성 제공)

> DB의 기본 단위 : 블록(정형, 비정형 모두)

### Hadoop Ecosystem

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gitdoj7tuej30gt0cnmyf.jpg) 

- 워크플로우 관리는 spring으로 만들어서 관리 



#### zookeeper

- 분산 환경에서 서버간의 산호 조정이 필요한 다양한 서비스를 제공하는 시스템 
- 하나의 서버에만 서비스 집중 되지 않게 서비스를 알맞게 분산해 동시에 처리하게 해줌
- 하나의 서버에서 처리한 결과를 다른 서버와도 동기화해서 데이터의 안정성을 보장
- 운영(active)서버에 문제가 발생해서 서비스를 제공하지 못할 경우 다른 대기중인 서버를 운영서버로 바꿔서 서비스가 중지 되지 않게 제공
- 분산 환경을 구성하는 서버들의 환경설정을 통합적으로 관리

#### Hbase

- HDFS 기반의 칼럼 기반 데이터베이스 
- 실시간 랜덤 조회 및 업데이트 가능(데이터는 수정 불가능)
- 각 프로세스는 개인의 데이터를 비동기적으로 업데이트
- 단, 맵리듀스는 일괄처리 방식으로 수행

#### Oozie

- 하둡 작업을 관리하는 워크플로우 및 코디네이터 시스템
- 자바 서블릿 컨테이너에서 실행되는 자바 웹 애플리케이션 서버(즉 톰켓이 설치되어야함)
- 맵리듀스 작업이나 피그(데이터 분석)작업 같은 특화된 액션으로 구성된 워크플로우를 제어 



#### Pig

- 복잡한 맵리듀스 프로그래밍을 대체할 Pig Latin 이라는 자체 언어 제공
- 맵리듀스 API를 크게 단순화함
- SQL과 유사한 형태. 단, SQL활용이 어려운 편임 

#### Hive

- 데이터웨어하우징용(여러개의 클러스터가 묶여있고 정형데이터를 관리) 솔루션
- SQL과 매우 유사한 **HiveQL**쿼리 제공(내부적으로 맵리듀스 잡으로 변환되어 실행됨)
- 자바를 모르는 데이터 분석가들도 쉽게 하둡 데이터를 분석할 수 있게 도와줌
- 짧은 임시 쿼리보다는 일괄적인 MapReduce처리에 이상적임 

> 데이터 웨어하우스 : 정형데이터 관리 
>
> hadoop : 비정형 데이터 관리
>
> spark는 정형/비정형 모두 빠름 -> 데이터웨어하우스 및 HDFS에 다 붙일 수 있음



#### Mahout

- 하둡기반으로 데이터 마이닝 알고리즘을 구현하였음
  - 분류 
  - 클러스터링
  - 추천 및 협업 필터링
  - 패턴 마이닝
  - 회귀분석
  - 차원 리덕션
  - 진화 알고리즘



#### Hcatalog

- 하둡으로 생성한 데이터를 테이블 및 스토리지 관리 서비스 

- 하둡 에코시스템 간의 상호운용성 향상에 큰 영향
- Hcatalog의 이용으로 Hive에서 생성한 테이블이나 데이터 모델을 Pig나 맵리듀스에서 손쉽게 이용할 수 잇음(이전엔 모델 공유는 간으햇으나, 상단하 백엔드 작업이 필요했음)

#### Avro

- RPC(Remote Procedure Call)과 데이터 직렬화를 지원
- JSON을 이용해 데이터 형식과 프로토콜을 정의 
- 작고 빠른 바이너리 포맷으로 데이터를 직렬화



#### Chukwa

- 분산 환경에서 생성되는 데이터를 HDFS에 안정적으로 저장하는 플랫폼
- 분산된 각 서버에서 에이전트(agent)를 실행하고, 콜렉터(Collector)가 에이전트로부터 데이터를 받아 HDFS에 저장
- 콜렉터 100개 에이전트당 하나씩 구동
- 데이터 중복 제거등 작업은 맵리듀스로 처리

#### Flume

- Chukwa처럼 분산된 서버에 에이전트가 설치되고, 에이전트로부터 데이터를 전달받는 콜렉터로 구성
- 전체 데이터의 흐름을 관리하는 마스터 서버가 있음
- 즉, 데이터를 어디서 수집, 어떤 방식으로 전송, 어디에 저장할지를 동적으로 변경가능(클라우데라 개발)

#### Scribe

- 데이터 수집플랫폼(페북 개발)
- 데이터를 중앙 집중서버로 전송
- 최종데이터는 HDFS외 다양한 저장소를 활용할 수 ㅣㅇㅆ음
- 설치와 구성이 쉽도록 다양한 프로그래밍 언어를 지원
- HDFS에 데이터를 저장하기 위해 JNI(Java Native Interface) 이용해야함 

#### Sqoop

- 대용량 데이터 전송 솔루션
- HDFS, RDBMS, DW, NoSQL 등 다양한 저장소에 대용량 데이터를 신속하게 전송할 수 있는 방법 제공
- 상용RDBMS도 지원하고, MySQL, PostgreSQL 오픈소스 RDMS도 지원함 

#### Hiho

- 대용량 데이터 전송 솔류션
- 하둡에서 데이터를 가져오기 위한 SQL을 지정할 수 있음
- JDBC 인터페이스 지원
- 오라클과 MySQL의 데이터 전송만 지원함 



## HDFS

- HDFS

  - Google의 GFS를 기반함 
  - 수십 테라바이트 또는 페타바이트 이상의 대용량 파일을 분산된 서버에 저장하고, 많은 클라이언트가 저장된 데이터를 빠르게 처리할 수 있게 설계된 파일 시스템
  - 저사양 서버를 이용해 스토리지를 구성할 수 잇음 
  - 대규모 데이터를 저장, 배치로 처리하는 경우 

  > zookeeper 머신 관리
  >
  > yarn 운영체제 관리
  
  

### 목적

1. 대용량 데이터 저장

- HDFS는 하나의 파일이 기가바이트에서 테라바이트 이상의 크기로 저장될 수 있게 설계
- 높은 데이터 전송 대역폭, 하나의 클러스터에서 수백대의 노드를 지원
- 하나의 인스턴스에서 수백만 개 이상의 파일을 지원

 

2. 데이터 무결성

- 데이터베이스에서 데이터 무결성이란, 데이터베이스에 저장되는 데이터가 일관성을 가지는 것을 의미

- 데이터의 입력이나 변경을 막아서 데이터의 안정성을 유지

- HDFS에서는 한번 저장된 데이터를 수정할 수 없고 읽기만 가능하게 해서 데이터 무결성을 유지

- 데이터의 수정은 불가능하지만 파일 이동, 삭제, 복사는 가능



3. 장애 복구

- HDFS는 장애를 빠른 시간에 감지하고 대처가 가능하다. 

- 데이터를 저장하면 복제 데이터도 함께 저장되어 데이터 유실을 방지
- 분산 서버간에 주기적으로 상태를 체크해 빠른 시간에 장애를 인지한다.(기본 블록당 3개를 복제하여 다른 데이터노드에 저장)



4. 스트리밍 방식의 데이터 접근

- HDFS는 클라이언트의 요청을 빠른 시간 내에 처리하는 것보다 동일한 시간 내에 더 많은 데이터를 처리하도록 설계
  - (이게 빠른 게 아닌가? 싶을 수 있다. 하지만 하둡은 <빠른 시간내의 데이터 처리>보다는 <데이터 양>에 중요성을 두고 있다는 것이다.)

- 클라이언트는 끊김 없이 연속된 흐름으로 데이터에 접근해야한다.
- 배치 작업과 높은 데이터 처리량을 위해 스트리밍 방식을 사용



## MapReduce

### Combiner

- 셔플(Shuffle)
  - 맵 태스크와 리듀스 태스크 사이의 데이터 전달 과정
  - 맵 태스크의 출력 데이터는 네트워크를 통해 리듀스 태스크로 전달됨
- 콤바이너 클래스
  - 셔플할 데이터의 크기를 줄이는데 도움을 줌

### MapReduce 용어

- job은 데이터들을 처리하는 mapper와 reducer들로 이루어진 완전한 프로그램 단위 
- Task는 Mapper나 Reducer의 각각의 실행 인스턴스
- Task Attempt는 한 머신에서 실행되는 특정 Task
- 용어 예제
  - job은 20개의 파일들을 입력으로 "Word Count"를 실행하는 것 
  - 20개의 입력 파일들은 20개의 Map Task들과 다수의 Reduce Task 들을 의미
  - 20개의 Map Task 들을 처리하기 위해서는 최소 20개의 Task Attempts가 있어야 하며 특정 Task가 실패할 경우 그 이상의 Task Attempts가 발생할 것임

- Job Data 분배
  - MapReduce 프로그램은 자바 묶음인 jar 파일과 실행 옵션 정보가 있는 Xml 파일로 로컬 머신에 저장이 됨 
  - MapReduce Job이 실행 될 때 위의 두 파일들은 HDFS에 저장이 되고 이 다운로드 위치 정보를 Task Tracker들에게 알려줌 
  - Task Tracker 내부적으로는 이 Binary들을 다운로드 받아서 로컬에 실행할 수 있는 환경(코드, 데이터, 클래스패스 등)을 구성함 
- 입력 데이터 분산
  - 모든 Mapper들은 기본적으로 동일함
  - 처리해야 할 데이터 블록이 있는 곳에서 Mapper를 실행하면 네트워크 트래픽을 줄일 수 있음
  - Reducer는 필연적으로 네트워크 트래픽이 발생하며 HDFS가 처리 
- MapReduce 성능 튜닝 
  - 콤바이너 클래스 적용
    - 콤바이너 클래스는 맵의 출력 데이터가 네트워크를 통해 리듀서로 전달되기 전 매퍼의 출려 ㄱ데이터의 크기를 줄임
  - 맵출력 데이터 압축 
    - 맵 출력 데이터를 압축하면, 파일 I/O와 네트워크 비용이 감소함 
  - DFS 블록 사이즈 수정
    - 같은 사이즈의 파일이라도 더 많은 수의 블록으로 분리되면, 그 만큼 많은 맵 태스크가 수행되어 더 빠르게 작업이 수행됨

- 클라이언트 

  - 맵리듀스 프로그램 & API

  



## 예제

1. 파일 다운 받기

   ```bash
   $ wget https://raw.githubusercontent.com/reillywatson/nasdaq-outliers/master/data/NASDAQ/NASDAQ_daily_prices_A.csv
   ```

2. 첫번째 라인을 지우고 저장

   ```bash
   sed -e '1d' NASDAQ_daily_prices_A.csv > NASDAQ_new.csv
   ```

3. hdfs에 input으로 저장 

   ```bash
   hadoop fs -put NASDAQ_new.csv /input
   ```

   

